:PROPERTIES:
:ID:       4505c8c1-33b2-46a4-8000-37484d944da9
:END:
#+title: Machine Learning

* 介绍
机器学习（Machine Learning）是制造 AI 的一个方法。

在原先，人们会从客观世界中总结、学习出规律和概念来，然后利用这些规律和概念来编程。机器学习主张的是，“肉身学习”这个过程因为现实世界的规律和“智能”这个概念太复杂了、规律太难以把握了，导致效率很低，不如直接让机器自己来学习。

我们可以把机器学习分成三个要素：

- 数据：数据是机器学习的基础。数据质量和数量对模型性能有直接影响。数据通常需要预处理，如清洗、归一化、 *特征* （feature）提取等。
- 模型：模型是用于从数据中学习的数学结构或函数，不同的模型适用于不同类型的问题（如线性回归用于回归问题，决策树用于分类问题）。
- 算法：算法是 *训练* 模型的具体方法或过程，它定义了如何从数据中提取模式并优化模型参数。常见算法包括梯度下降、随机森林、支持向量机等。

从上面的三要素可以看出，数据就是客观世界的一个反映，算法就是学习方法，学习后提炼出的 *模式和关系* （也就是知识）都存放在模型中。最后放上一张 ML 的总结图：

[[file:img/clipboard-20250122T134321.png]]

* 分类
ML 的分类如下图所示：

[[file:img/clipboard-20250122T144047.png]]

分类的依据如下：

[[file:img/clipboard-20250122T144110.png]]

可以看到分类依据非常不严谨，神经网络是模型的种类，而强化学习是算法的种类，而划分经典机器学习的则是数据有无标注的特性。我觉得这可能和 ML 近些年的野蛮生长有关，传统方法的理论并不能适配新兴的范式。

我看有些博客在纠结于 LLM 是不是监督学习或者无监督学习，我觉得领会意思就够了，辩经就没有意思了。毕竟理论还没有发展完善。

** Classical Method
传统的机器学习方法（1950 年就提出了），分为监督学习和非监督学习两类，这两类其实对应了两种“学习模式”。即在有标准答案（有标注 label）的情况下完成学习，和在没有标准答案的情况下，发现规律。

其类型如下：

[[file:img/clipboard-20250122T145135.png]]

*** Supervisor Method
监督学习可以分为分类（Classification）和回归（Regression）两种。

分类主要用于语言检测、垃圾邮件过滤等。典型方法包括 [[id:832cdfa5-83f8-4af8-bbd5-940437ebe47d][支持向量机]] 、[[id:fc0c9dd1-e137-4bc1-84f4-633d7089ce5f][朴素贝叶斯]] 、[[id:ccbc2aab-3c63-4ce1-ac4a-e1d51013c561][决策树]] 等。

回归就是拟合，我好像在哪里看过，回归的意思就是说，数据点都会回归到我们拟合出的那个曲线上。

*** Unsupervisor Method
无监督学习（在 90 年代发明）可以避免数据标注的成本。可以分为聚类（Clustering）、降维（Dimisionality Reduction）、关联规则学习（Association Rule Learning）三种。

聚类是根据未知特征来划分对象，这是它与分类算法的区别。常用于市场细分、压缩图像（识别相似的颜色）、分析和标记新数据、检测异常行为。典型方法包括 K-Mean 、Mean-Shift 、DBSCAN 。

降维指的是找到最核心的特征，舍弃那些不重要的特征。常用于推荐系统。典型方法包括主成分分析（PCA）、奇异值分解（SVD）、潜在狄利克雷分配（LDA）、潜在语义分析（LSA、pLSA、GLSA）。

关联规则学习指的是分析不同特征数据之间的联系。用于“猜你喜欢”。典型方法包括 Apriori、Euclat、FP-growth 。

** Reinforcement Learning
强化学习不再提供给模型数据，而是提供给模型一个环境，并且给模型提供环境反馈。模型会在反馈中不断试错进步，也就是如下思路。

[[file:img/clipboard-20250122T161736.png]]

强化学习广泛用于自动驾驶、扫地机器人、游戏（下围棋的 AlphaGo 就是强化学习）、自动化交易等领域。经典方法有 Q-Learning 、 SARSA 、DQN、 A3C 、遗传算法。

** Ensemble Method
Ensemble method 中文译名应该是“集成学习”。它通过组合多个模型来提高预测性能和鲁棒性。通过结合多个模型的预测结果，可以减少单个模型的偏差和方差，从而提高整体预测的准确性和稳定性。

常见的 Ensemble 方法包括：

- Bagging(Bootstrap Aggregating)：通过在原始数据集上采样多个子集来训练多个模型，然后将其预测结果进行平均（用于回归问题）或投票（用于分类问题）。
- Boosting：逐步训练模型，每个新的模型尝试纠正前一个模型的错误，重点关注难以预测的训练样本。包括 AdaBoost、梯度提升（Gradient Boosting）、XGBoost、LightGBM 等。
- Stacking：使用多个基础模型生成预测结果，然后用另一个模型（称为元模型）来组合这些预测，以生成最终预测。
- Voting：将多个模型的预测结果进行投票，选择票数最多的类别作为最终预测。这可以是硬投票（直接投票）或软投票（基于概率的加权平均）。适用于分类问题。

** Neural Network
*** 语义空间
我们都知道人工神经网络中每一层的神经网络都可以对前一层输入进行一次矩阵运算（如果刨除激活不算的话），从线性代数的知识可知，这其实是在做一次空间映射，如果矩阵是 ~M x N~ 的，那么每经过一层，就是将一个原本在 ~M~ 维空间向量映射到一个 ~N~ 维的空间中。

人工神经网络的原理是将一段数据先 tokenize ，也就是将原本的字符串之类（比如我们和 chatgpt 说的话）的东西转换成一组一维的标量，每个标量被称为一个 token ，然后将他们映射到一个向量空间中，这个过程叫做“嵌入”（embedding），然后就是对于这个向量的一次次映射。

那么我们这样做的直观理解是什么，我觉得是这样的，人工神经网络是在描述语义。说白了，就是通过构建一个语义空间的方式去掌握各个 token 的语义，语义空间就是一个多维向量空间。那么为什么一个多维向量空间就可以描述语义呢？因为多维向量空间中存在距离，我们可以用距离的方式来描述两个 token 的相似性，而这就构成了语义。比如在一个空间中，当我们观测到“苹果，梨，香蕉”的距离很近，那么可能就是因为她们都具有水果的语义。

语义空间的设计有两个极端，一个是一维标量，另一个是独热码。如果用一维标量的话，有些复杂的语义没有办法表示，比如说“苹果”，它既有“水果”的意思，又有“电子品牌”的意思，那么它应该既和“香蕉”离得近，又和“三星”离得近，但是“香蕉”和“三星”不应该离那么近。而独热码则是尽可能的扩大自己的维度，并只使用一个维度，那么我们很难表示出相近的含义，因为独热码的所有点的距离都是相同的。

*** No Deep Leanring
非深度学习的神经网络通常被称为“浅层神经网络”。它们通常具有较少的层数，通常只有一到两层隐藏层，与深度学习模型中可能有数十甚至上百层的神经网络相比，层数明显较少。

非深度学习的人工神经网络往往不能单独作为类别，而应当被划归到传统机器学习的范畴内。

- 感知机（Perceptron）：最基本的神经网络结构，具有单个神经元，用于线性分类任务。
- 多层感知机（MLP, Multi-Layer Perceptron）：包含一个或多个隐藏层的神经网络。用于各种简单的回归和分类任务。通常只有一到两层隐藏层时被认为是浅层网络。

*** Deep Learning
因为采用了人工神经网络，导致深度学习与其他机器学习方法（也称作“传统机器学习方法”）有许多不同：

- 数据依赖程度：传统机器学习适合数据量较小的任务，深度学习适合处理大数据。
- 硬件依赖程度：深度学习十分依赖于硬件设施，因为计算量实在太大。它会涉及很多矩阵运算，因此很多深度学习都要求有 GPU 参与运算。
- 特征工程：在训练一个机器学习模型的时候，需要首先确定学习哪些特征，比如识别人脸可能并不需要身高特征。在传统机器学习方法中，几乎所有特征都需要人为确认后，再进行手工特征编码。而深度学习试图自己从数据中自动学习特征。
- 解决问题的方式：传统机器学习通常先把问题分成几块，一个个地解决好之后，再重新组合。深度学习是一次性地解决好问题。
- 训练和推理运行时间：传统机器学习的训练时间快而推理时间慢，深度学习的训练时间慢而推理时间快。

DL 的典型模型如下：

- CNN
- RNN
- Autoencoders
- Transformer
  
